{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "666df20b-8a09-4403-bb7b-b26b49ad9e2d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# GRAVITATIONAL LENS SDSSJ0819+5356"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15790fc4-487e-454c-a992-a8d7d51490ac",
   "metadata": {},
   "source": [
    "#### Stars study with Imaphot + Lens study with Imaphot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c227781-54c0-4b39-804d-c54f07523717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Packages\n",
    "import utilfunctions as uf\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import ticker\n",
    "from astropy.nddata.utils import Cutout2D\n",
    "import functions\n",
    "import cupy as cp\n",
    "from cupyx.scipy.ndimage import minimum_filter\n",
    "import numpy as np\n",
    "from skimage import exposure\n",
    "from astropy.wcs import WCS\n",
    "import psycopg2\n",
    "import os\n",
    "from astropy.io import fits\n",
    "import io\n",
    "from astropy.wcs import WCS\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib import ticker\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1135033f-c4f5-48e7-9df0-a1117f6f81a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Paths of the gravitational lens\n",
    "images_paths_QHY, images_paths_iKon, images_paths_all = uf.images_paths(\"SDSSJ0819+5356\", directory_path = \"work/red\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7093839-32e2-4cf4-9969-f7b0d705f225",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Components coordinates\n",
    "coordsA=[124.998243440, 53.940423310]#A\n",
    "coordsB=[125.00007152, 53.93966377] #B ra_decB = w_image.pixel_to_world( xA+3.367/0.507, yA+2.226/0.507)\n",
    "coordsG=[124.999185780, 53.940057240] #G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f55f52b-97f5-4bdd-88fd-ef282fb17222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot Lens\n",
    "with fits.open(images_paths_iKon[100], memmap=True) as hdu:\n",
    "\n",
    "    image, w_image, header, dateob, filter, fwhms, sky,EXPT1 = uf.getinfo(hdu)\n",
    "    #print(header)\n",
    "    xA, yA = uf.radec_to_xy(coordsA, w_image)\n",
    "    xB, yB = uf.radec_to_xy(coordsB, w_image)\n",
    "    xG, yG = uf.radec_to_xy(coordsG, w_image) \n",
    "    #ra_decB = w_image.pixel_to_world( xA+3.367/0.507, yA+2.226/0.507)\n",
    "    #xB, yB = uf.radec_to_xy([ra_decB.ra.deg, ra_decB.dec.deg], w_image)\n",
    "    normalized_image = exposure.rescale_intensity(image.get(), in_range='image', out_range=(0, 1))\n",
    "    plt.imshow(normalized_image, vmin=0, vmax=0.015)\n",
    "\n",
    "    plt.plot( xA, yA, \"x\", mec='g', ms=15)#A\n",
    "    plt.plot( xA+3.367/0.507, yA+2.226/0.507, \"x\", mec='r', ms=15)#B\n",
    "    plt.plot( xB, yB, \"x\", mec='b', ms=15)#A\n",
    "    plt.plot( xG, yG, \"x\", mec='w', ms=15)#G\n",
    "    plt.plot( xA+1.980/0.507, yA+1.348/0.507, \"x\", mec='w', ms=15)#G\n",
    "\n",
    "    plt.xlim( xA+20, xA-20)\n",
    "    plt.ylim( yA+20, yA-20)\n",
    "\n",
    "    ra_decB = w_image.pixel_to_world( xA+3.367/0.507, yA+2.226/0.507)\n",
    "    print(ra_decB,  xG, yG)\n",
    "    xB, yB = uf.radec_to_xy([ra_decB.ra.deg, ra_decB.dec.deg], w_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7345811b-9615-4ea6-b71b-3817f577f27d",
   "metadata": {},
   "source": [
    "# ________________________________________________________________________________________\n",
    "## STARS STUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3b36fa-687e-4eaa-8ae2-af02ba785abc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "coords = cp.asarray([[124.998243440, 53.940423310],[124.999185780, 53.940057240],[125.037078920, 53.968357790], [125.013046340, 53.934497430], [125.010332700, 53.927527680], [125.024931110, 53.921033100], [125.023014140, 53.950554040]])#[[125.037078920, 53.968357790], [125.013046340, 53.934497430], [125.012248390, 53.931427250], [125.010332700, 53.927527680], [124.985519970, 53.943565380], [125.024931110, 53.921033100], [124.985143180, 53.950553540], [125.023014140, 53.950554040]]) # D, E, F, G, H, I, J, K\n",
    "print(len(coords))\n",
    "stars=[\"A\", \"B\", \"D\", \"E\", \"G\", \"I\", \"K\"]\n",
    "with fits.open(images_paths_iKon[100], memmap=True) as hdu:\n",
    "    image, w_image, header, dateob, filter, fwhms, sky,EXPT1 = uf.getinfo(hdu)\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for r,i in enumerate(coords):\n",
    "        \n",
    "        x0, y0 = uf.radec_to_xy(i.get(), w_image)\n",
    "        x.append(x0)\n",
    "        y.append(y0)\n",
    "\n",
    "plt.imshow(image.get(), vmin=200, vmax=1000, cmap='gray' )\n",
    "for j, k  in enumerate(x):\n",
    "    if j == 0:\n",
    "        plt.text(k-4, y[j]-4, stars[j],  color='white')\n",
    "    elif j == 5:\n",
    "        plt.text(k+10, y[j]+10, stars[j],  color='white')\n",
    "    else:\n",
    "        plt.text(k+15, y[j]+15, stars[j],  color='white')\n",
    "height, width = image.shape\n",
    "plt.annotate('', xy=(425, 1275), xytext=(425, 1200),arrowprops=dict(facecolor='white', edgecolor='white', arrowstyle='<-'),color='white')\n",
    "plt.annotate('', xy=(422, 1272), xytext=(500, 1272),arrowprops=dict(facecolor='white', edgecolor='white', arrowstyle='<-'),color='white')\n",
    "plt.annotate('N', xy=(425, 1200), xytext=(-5, 2),  textcoords='offset points', color='white', fontsize=10)\n",
    "plt.annotate('E', xy=(500, 1272), xytext=( -8, -3),  textcoords='offset points', color='white', fontsize=10)\n",
    "# Plot double horizontal arrows at position (800, 1275)\n",
    "plt.annotate(\n",
    "    '', xy=(850, 1275), xytext=(800, 1275),\n",
    "    arrowprops=dict(facecolor='white', edgecolor='white', arrowstyle='<|-|>')\n",
    ")\n",
    "\n",
    "# Annotate with text \"25.5\" over the arrows\n",
    "plt.annotate(\n",
    "    '25.5\"', xy=(820, 1275), xytext=(0, 5),\n",
    "    textcoords='offset points', color='white', fontsize=10,\n",
    "    ha='center', va='bottom'\n",
    ")\n",
    "plt.xlim(900, 400)\n",
    "plt.ylim(1300, 800)\n",
    "\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig('SDSSJ0819+5356_field.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a2f7c7-51b9-48dd-8630-646417f826f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to DB\n",
    "conn = psycopg2.connect(database=\"astrodb\",\n",
    "                        host=\"10.0.210.30\",\n",
    "                        user=\"read_only\",\n",
    "                        password=\"read_only\",\n",
    "                        port=\"5433\")\n",
    "\n",
    "# MODIFY these parameters (object 2)\n",
    "# MODIFY these parameters\n",
    "cursor = conn.cursor()\n",
    "start_date = datetime.datetime(2023,1, 1,0,0,0)\n",
    "end_date = datetime.datetime.now()\n",
    "\n",
    "tolerance_small = 1/3600 # This is the tolerance to find objects in imaphot.\n",
    "tolerance_big = 0.5 # This is used to pre-select relevant images on imastats. It should be approx the FOV of the images.\n",
    "fluxstars={}\n",
    "\n",
    "for i, c in enumerate(coords):\n",
    "    ra = float(c[0])\n",
    "    dec = float(c[1].get())\n",
    "    cursor = conn.cursor()\n",
    "    search_tuple = (ra, dec, tolerance_big, start_date, end_date, ra, dec, tolerance_small)\n",
    "    cursor.execute(\"\"\"SELECT imaphot.imageid, imastats.dateobs, imastats.header -> 'JD-OBS' AS jdobs, imaphot.ra, imaphot.dec, imaphot.flux, imaphot.dflux, CAST(imastats.header -> 'ZP' AS real) as zp, imastats.exptime, imastats.filter FROM imaphot JOIN imastats ON imaphot.imageid = imastats.imageid WHERE imaphot.imageid IN ( SELECT imageid FROM imastats WHERE q3c_radial_query(centralra, centraldec, %s, %s, %s) AND dateobs> %s AND dateobs< %s) AND q3c_radial_query(ra, dec, %s, %s, %s);\"\"\", search_tuple)\n",
    "    data=cursor.fetchall()\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = [\"IMAGEID\", \"DATEOBS\", \"JD-OBS\", \"RA\", \"DEC\", \"FLUX\", \"DFLUX\", \"ZP\", \"EXPTIME\", \"FILTER\"]\n",
    "    df[\"MAG\"] = df[\"ZP\"]-2.5*np.log10(df[\"FLUX\"]/df[\"EXPTIME\"])\n",
    "    cursor.close()\n",
    "    fluxstars[stars[i]] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0771d0-cdd9-4acd-945f-e4b5a6b19fc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "dfs2 = []\n",
    "for i in fluxstars:\n",
    "    df_subset = fluxstars[i][['IMAGEID', \"JD-OBS\", \"FILTER\", 'FLUX']]\n",
    "    df_subset2 = fluxstars[i][['IMAGEID', \"JD-OBS\", \"FILTER\", \"DFLUX\"]]\n",
    "    dfs.append(df_subset)\n",
    "    dfs2.append(df_subset2)\n",
    "    \n",
    "merged_df = dfs[0]\n",
    "errormerged_df = dfs2[0]\n",
    "for i, df in enumerate(dfs[1:]):\n",
    "    merged_df = pd.merge(merged_df, df, on=['IMAGEID',\"JD-OBS\", \"FILTER\"], how='outer', suffixes=(\"_\"+ stars[i],\"_\"+stars[i+1]))\n",
    "# merged_df.rename(columns={\"FLUX\": \"FLUX_\"+stars[-1]}, inplace=True)\n",
    "    if i == len(dfs) - 2:\n",
    "        merged_df.rename(columns={\"FLUX\": \"FLUX_\" + stars[i+1]}, inplace=True)\n",
    "\n",
    "for i, df in enumerate(dfs2[1:]):\n",
    "    errormerged_df = pd.merge(errormerged_df, df, on=['IMAGEID',\"JD-OBS\", \"FILTER\"], how='outer', suffixes=(\"_\"+ stars[i],\"_\"+stars[i+1]))\n",
    "    if i == len(dfs2) - 2:\n",
    "        errormerged_df.rename(columns={\"DFLUX\": \"DFLUX_\" + stars[i+1]}, inplace=True)\n",
    "# errormerged_df.rename(columns={\"DFLUX\": \"DFLUX_J\"}, inplace=True)\n",
    "\n",
    "for i in range(len(stars)):\n",
    "    merged_df = merged_df[merged_df[\"FLUX_\"+stars[i]].notna()] \n",
    "    errormerged_df = errormerged_df[errormerged_df[\"DFLUX_\"+stars[i]].notna()]\n",
    "\n",
    "print(merged_df) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c974cd84-bdc5-4e80-ab5d-2ecaa582b78d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_values = merged_df[\"FILTER\"].unique()\n",
    "fluxstars = {} # Dataframes flux star per filter\n",
    "errorfluxstars = {} # Dataframes error_flux star per filter\n",
    "dateobs = {}\n",
    "for i, filters in enumerate(unique_values):\n",
    "    fluxstars[f\"{filters}\"] = merged_df[merged_df[\"FILTER\"] == filters].drop(merged_df.keys()[:3], axis=1)\n",
    "    errorfluxstars[f\"{filters}\"] = errormerged_df[errormerged_df[\"FILTER\"] == filters].drop(errormerged_df.keys()[:3], axis=1)\n",
    "    dateobs[f\"{filters}\"] = merged_df[merged_df[\"FILTER\"] == filters][\"JD-OBS\"]\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c73cf20-97e3-4e92-8dff-5ba5eec1ff31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff_phot, diff_phot_names, diff_phot_dates = star_diff_phot(fluxstars, dateobs, unique_values, stars)\n",
    "error, errordiff_phot_names = error_diff_phot(fluxstars, errorfluxstars, unique_values, stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf6a13a-48fd-43c8-a4ed-e6d4b79228dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "¿a=[250,250,250,250,250,250,250,250,250,250,250,250,250,250,250,250,250,250,250]\n",
    "for o, t in enumerate(diff_phot):\n",
    "    print(len(diff_phot[t]), len(diff_phot[t][\"filter_Lum\"]))\n",
    "    \n",
    "    figure, axis = plt.subplots(len(diff_phot[t]), len(diff_phot[t][\"filter_Lum\"]),figsize=(a[o], 60))\n",
    "    figure.tight_layout(pad=3.5)\n",
    "    for i, filtre in enumerate(diff_phot[t]):\n",
    "        for j, phot in enumerate(diff_phot[t][filtre]):\n",
    "        \n",
    "            axis[i][j].errorbar(diff_phot_dates[t]['filter_' + unique_values[i]][j]-2460000.0, phot, yerr=np.std((phot[np.logical_not(np.isnan(phot))])), elinewidth=0.75, linewidth=0,   marker=\".\", label = f\"σ = {np.std((phot[np.logical_not(np.isnan(phot))]))}\")\n",
    "            axis[i][j].legend()\n",
    "            #axis[i][j].set_ylim([np.mean(group3_2[i][j][np.logical_not(np.isnan(group3_2[i][j]))])-10*np.std(group3_2[i][j][np.logical_not(np.isnan(group3_2[i][j]))]),np.mean(group3_2[i][j][np.logical_not(np.isnan(group3_2[i][j]))])+10*np.std(group3_2[i][j][np.logical_not(np.isnan(group3_2[i][j]))])])\n",
    "            axis[i][j].set(xlabel='Time JD-2460000', ylabel='Phot. Diff.')\n",
    "            axis[i][j].set_title(\"Filter \"+unique_values[i]+ \" star \" + diff_phot_names[t]['filter_' + unique_values[i]][j][0]+ \" and ref. star \" + diff_phot_names[t]['filter_' + unique_values[i]][j][1:] )\n",
    "    \n",
    "    plt.show()\n",
    "    #plt.savefig('diff_phot_stars_astroDB'+str(t)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3fda9-3370-4f02-ad71-c325a34b2f74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "diff_phot_dates2 = copy.deepcopy(diff_phot_dates)\n",
    "combosbonesfiltre={}\n",
    "combosbonesfiltrenom={}\n",
    "for o, t in enumerate(diff_phot):\n",
    "    std2=[]\n",
    "    stdpercentile2=[]\n",
    "    combos2sorted=[]\n",
    "    minfiltre={}\n",
    "    minfiltrenom={}\n",
    "    for i, filters in enumerate(diff_phot[t]):\n",
    "        if i>=0:\n",
    "            stdinter=[]\n",
    "            stdpercentileinter=[]\n",
    "            #count=0\n",
    "            for j, combo in enumerate(diff_phot[t][filters]):\n",
    "                deletepositions2=[]\n",
    "                # for o, l in enumerate(np.logical_not(np.isnan(combo))):\n",
    "                    # if l == np.bool_(False):\n",
    "                        # diff_phot_dates2[t][filters][j] = np.delete(diff_phot_dates2[t][filters][j], o)\n",
    "\n",
    "                combo=(combo)[np.logical_not(np.isnan(combo))]    \n",
    "\n",
    "                for k in combo:\n",
    "                    if k < np.quantile(combo, 0.1) or k > np.quantile(combo, 0.9):     \n",
    "                        deletepositions2.append(np.where(combo == k)[0][0])  \n",
    "                combo = np.delete(combo, deletepositions2)\n",
    "                # diff_phot_dates2[t][filters][j] = np.delete(diff_phot_dates2[t][filters][j], deletepositions2)\n",
    "                \n",
    "                stdinter.append(np.std(combo))\n",
    "                stdpercentileinter.append(np.std(combo))\n",
    "                #count+=1\n",
    "            sortered = sorted(zip(stdpercentileinter,stdinter,diff_phot_names[t][filters]))\n",
    "\n",
    "            std2.append([x[1] for x in sortered])\n",
    "            stdpercentile2.append([x[0] for x in sortered])\n",
    "            combos2sorted.append([x[2] for x in sortered])\n",
    "            minfiltre[filters] = ([x[0] for x in sortered][0])\n",
    "            minfiltrenom[filters] = ([x[2] for x in sortered][0])\n",
    "\n",
    "    # figure, axis = plt.subplots(1, len(stdpercentile2),figsize=(60, 10))\n",
    "    # figure.tight_layout(pad=3.5)\n",
    "    combosbonesfiltre[t] = minfiltre\n",
    "    combosbonesfiltrenom[t] = minfiltrenom\n",
    "#     for i in range(len(stdpercentile2)):\n",
    "\n",
    "#         #bars=axis[i].bar(combos3sorted[i], stdpercentile[i])\n",
    "#         roundvalues=[round(val, 4) for val in stdpercentile2[i]]\n",
    "#         axis[i].bar_label(axis[i].bar(combos2sorted[i], stdpercentile2[i]), labels = roundvalues, rotation=90)\n",
    "#         axis[i].set(xlabel='Star groups', ylabel='Standard deviation')\n",
    "#         axis[i].set_title(\"Filter \"+ unique_values[i])\n",
    "#         axis[i].tick_params(axis='x', rotation=90)\n",
    "        \n",
    "    #plt.savefig('standarddeviation_astroDB'+str(t)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83018215-2540-47c5-9a99-7fc0f1ff3cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, r in enumerate(combosbonesfiltre):\n",
    "    print(r)\n",
    "    for j, l in enumerate(combosbonesfiltre[r]):\n",
    "        print(l)\n",
    "        print(combosbonesfiltrenom[r][l],combosbonesfiltre[r][l])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8ff7d-f6de-42e4-8a9e-61ffbc5e434b",
   "metadata": {},
   "source": [
    "# __________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d443a5-baa3-4c0e-9480-00341277a8d7",
   "metadata": {},
   "source": [
    "## LENS STUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed005f6-5aa2-4d9d-a168-850147ed9e61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Connect to DB\n",
    "conn = psycopg2.connect(database=\"astrodb\",\n",
    "                        host=\"10.0.210.30\",\n",
    "                        user=\"read_only\",\n",
    "                        password=\"read_only\",\n",
    "                        port=\"5433\")\n",
    "\n",
    "# MODIFY these parameters\n",
    "cursor = conn.cursor()\n",
    "start_date = datetime.datetime(2023,1, 1,0,0,0)\n",
    "end_date = datetime.datetime.now()\n",
    "# D, E, F[125.012248390, 53.931427250], G, H[124.985519970, 53.943565380], I, J[124.985143180, 53.950553540], K\n",
    "coordsstars = cp.asarray([[125.037078920, 53.968357790], [125.013046340, 53.934497430], [125.010332700, 53.927527680], [125.024931110, 53.921033100], [125.023014140, 53.950554040]]) # D, E, G, I, K\n",
    "coordslens = cp.asarray([[124.998243440, 53.940423310],[124.999185780, 53.940057240]]) # A,  G ---B,,[125.00007152, 53.93966377]\n",
    "\n",
    "stars=[\"D\", \"E\", \"G\", \"I\", \"K\"]\n",
    "lens=[\"A\", \"GB\"]#---\"B\",\n",
    "\n",
    "tolerance_small = 1/3600 # This is the tolerance to find objects in imaphot.\n",
    "tolerance_big = 0.5 # This is used to pre-select relevant images on imastats. It should be approx the FOV of the images.\n",
    "\n",
    "\n",
    "# STARS\n",
    "fluxstars={}\n",
    "for i, c in enumerate(coordsstars):\n",
    "    ra = float(c[0].get())\n",
    "    dec = float(c[1].get())\n",
    "    cursor = conn.cursor()\n",
    "    search_tuple = (ra, dec, tolerance_big, start_date, end_date, ra, dec, tolerance_small)\n",
    "    cursor.execute(\"\"\"SELECT imaphot.imageid, imastats.dateobs, imastats.header -> 'JD-OBS' AS jdobs, imaphot.ra, imaphot.dec, imaphot.flux, imaphot.dflux, CAST(imastats.header -> 'ZP' AS real) as zp, imastats.exptime, imastats.filter FROM imaphot JOIN imastats ON imaphot.imageid = imastats.imageid WHERE imaphot.imageid IN ( SELECT imageid FROM imastats WHERE q3c_radial_query(centralra, centraldec, %s, %s, %s) AND dateobs> %s AND dateobs< %s) AND q3c_radial_query(ra, dec, %s, %s, %s);\"\"\", search_tuple)\n",
    "    data=cursor.fetchall()\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = [\"IMAGEID\", \"DATEOBS\", \"JD-OBS\", \"RA\", \"DEC\", \"FLUX\", \"DFLUX\", \"ZP\", \"EXPTIME\", \"FILTER\"]\n",
    "    df[\"MAG\"] = df[\"ZP\"]-2.5*np.log10(df[\"FLUX\"]/df[\"EXPTIME\"])\n",
    "    cursor.close()\n",
    "    fluxstars[stars[i]] = df\n",
    "\n",
    "# COMPONENTS+Galaxy\n",
    "fluxcomp={}\n",
    "for i, c in enumerate(coordslens):\n",
    "    ra = float(c[0].get())\n",
    "    dec = float(c[1].get())\n",
    "    cursor = conn.cursor()\n",
    "    search_tuple = (ra, dec, tolerance_big, start_date, end_date, ra, dec, tolerance_small)\n",
    "    cursor.execute(\"\"\"SELECT imaphot.imageid, imastats.dateobs, imastats.header -> 'JD-OBS' AS jdobs, imaphot.ra, imaphot.dec, imaphot.flux, imaphot.dflux, CAST(imastats.header -> 'ZP' AS real) as zp, imastats.exptime, imastats.filter FROM imaphot JOIN imastats ON imaphot.imageid = imastats.imageid WHERE imaphot.imageid IN ( SELECT imageid FROM imastats WHERE q3c_radial_query(centralra, centraldec, %s, %s, %s) AND dateobs> %s AND dateobs< %s) AND q3c_radial_query(ra, dec, %s, %s, %s);\"\"\", search_tuple)\n",
    "    data=cursor.fetchall()\n",
    "    df = pd.DataFrame(data)\n",
    "    df.columns = [\"IMAGEID\", \"DATEOBS\", \"JD-OBS\", \"RA\", \"DEC\", \"FLUX\", \"DFLUX\", \"ZP\", \"EXPTIME\", \"FILTER\"]\n",
    "    df[\"MAG\"] = df[\"ZP\"]-2.5*np.log10(df[\"FLUX\"]/df[\"EXPTIME\"])\n",
    "    cursor.close()\n",
    "    fluxcomp[lens[i]] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c524bee-f626-4e2e-b802-0a587fa1b093",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STARS\n",
    "dfs = []\n",
    "dfs2 = []\n",
    "for i in fluxstars:\n",
    "    df_subset = fluxstars[i][['IMAGEID', \"JD-OBS\", \"FILTER\", 'FLUX']]\n",
    "    df_subset2 = fluxstars[i][['IMAGEID', \"JD-OBS\", \"FILTER\", \"DFLUX\"]]\n",
    "    dfs.append(df_subset)\n",
    "    dfs2.append(df_subset2)\n",
    "    \n",
    "merged_df = dfs[0]\n",
    "errormerged_df = dfs2[0]\n",
    "for i, df in enumerate(dfs[1:]):\n",
    "    merged_df = pd.merge(merged_df, df, on=['IMAGEID',\"JD-OBS\", \"FILTER\"], how='outer', suffixes=(\"_\"+ stars[i],\"_\"+stars[i+1]))\n",
    "# merged_df.rename(columns={\"FLUX\": \"FLUX_\"+stars[-1]}, inplace=True)\n",
    "    if i == len(dfs) - 2:\n",
    "        merged_df.rename(columns={\"FLUX\": \"FLUX_\" + stars[i+1]}, inplace=True)\n",
    "\n",
    "for i, df in enumerate(dfs2[1:]):\n",
    "    errormerged_df = pd.merge(errormerged_df, df, on=['IMAGEID',\"JD-OBS\", \"FILTER\"], how='outer', suffixes=(\"_\"+ stars[i],\"_\"+stars[i+1]))\n",
    "    if i == len(dfs2) - 2:\n",
    "        errormerged_df.rename(columns={\"DFLUX\": \"DFLUX_\" + stars[i+1]}, inplace=True)\n",
    "# errormerged_df.rename(columns={\"DFLUX\": \"DFLUX_J\"}, inplace=True)\n",
    "\n",
    "for i in range(len(stars)):\n",
    "    merged_df = merged_df[merged_df[\"FLUX_\"+stars[i]].notna()] \n",
    "    errormerged_df = errormerged_df[errormerged_df[\"DFLUX_\"+stars[i]].notna()]\n",
    "\n",
    "#print(merged_df) \n",
    "\n",
    "# COMPONENTS + Galaxy\n",
    "dfs = []\n",
    "dfs2 = []\n",
    "for i in fluxcomp:\n",
    "    df_subset = fluxcomp[i][['IMAGEID', \"JD-OBS\", \"FILTER\", 'FLUX']]\n",
    "    df_subset2 = fluxcomp[i][['IMAGEID', \"JD-OBS\", \"FILTER\", \"DFLUX\"]]\n",
    "    dfs.append(df_subset)\n",
    "    dfs2.append(df_subset2)\n",
    "    \n",
    "merged_dfcomp = dfs[1]\n",
    "errormerged_dfcomp = dfs2[1]\n",
    "#for i, df in enumerate(dfs[1:]):\n",
    "#    merged_dfcomp = pd.merge(merged_dfcomp, df, on=['IMAGEID',\"JD-OBS\", \"FILTER\"], how='outer', suffixes=(\"_\"+ lens[i],\"_\"+lens[i+1]))\n",
    "# merged_df.rename(columns={\"FLUX\": \"FLUX_\"+stars[-1]}, inplace=True)\n",
    "#    if i == len(dfs) - 2:\n",
    "#        merged_dfcomp.rename(columns={\"FLUX\": \"FLUX_\" + lens[i+1]}, inplace=True)\n",
    "\n",
    "#for i, df in enumerate(dfs2[1:]):\n",
    "#    errormerged_dfcomp = pd.merge(errormerged_dfcomp, df, on=['IMAGEID',\"JD-OBS\", \"FILTER\"], how='outer', suffixes=(\"_\"+ lens[i],\"_\"+lens[i+1]))\n",
    "#    if i == len(dfs2) - 2:\n",
    "#        errormerged_dfcomp.rename(columns={\"DFLUX\": \"DFLUX_\" + lens[i+1]}, inplace=True)\n",
    "# errormerged_df.rename(columns={\"DFLUX\": \"DFLUX_J\"}, inplace=True)\n",
    "#print(merged_dfcomp) \n",
    "#for i in range(len(lens)):\n",
    "merged_dfcomp = merged_dfcomp[merged_dfcomp[\"FLUX\"].notna()] #_\"+lens[i]\n",
    "errormerged_dfcomp = errormerged_dfcomp[errormerged_dfcomp[\"DFLUX\"].notna()]\n",
    "#print(merged_dfcomp) \n",
    "\n",
    "merged_dftot = pd.merge(merged_df, merged_dfcomp, on=['IMAGEID',\"JD-OBS\", \"FILTER\"], how='inner')\n",
    "errormerged_dftot = pd.merge(errormerged_df, errormerged_dfcomp, on=['IMAGEID',\"JD-OBS\", \"FILTER\"], how='inner')\n",
    "#print(merged_dftot) \n",
    "print(merged_dftot)\n",
    "#for i in range(len(nomc)):    \n",
    "merged_dftot = np.split(merged_dftot, [3, 3+len(stars)], axis=1 )\n",
    "errormerged_dftot = np.split(errormerged_dftot, [3, 3+len(stars)], axis=1 )\n",
    "\n",
    "starsflux = pd.concat([merged_dftot[0],merged_dftot[1]], axis=1)\n",
    "componentsflux = pd.concat([merged_dftot[0],merged_dftot[2]], axis=1)\n",
    "estarsflux = pd.concat([errormerged_dftot[0],errormerged_dftot[1]], axis=1)\n",
    "ecomponentsflux = pd.concat([errormerged_dftot[0],errormerged_dftot[2]], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fae3791-2a31-4352-b98c-6dcf0ae8a62e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "unique_values = merged_dftot[0][\"FILTER\"].unique()\n",
    "fluxstars = {} # Dataframes flux star per filter\n",
    "errorfluxstars = {} # Dataframes error_flux star per filter\n",
    "fluxcomponents = {} # Dataframes flux components per filter\n",
    "errorfluxcomponents = {} # Dataframes error_flux components per filter\n",
    "dateobs = {}\n",
    "ids ={}\n",
    "for i, filters in enumerate(unique_values):\n",
    "    fluxstars[f\"{filters}\"] = starsflux[starsflux[\"FILTER\"] == filters].drop(starsflux.keys()[:3], axis=1)\n",
    "    errorfluxstars[f\"{filters}\"] = estarsflux[estarsflux[\"FILTER\"] == filters].drop(starsflux.keys()[:3], axis=1)\n",
    "    fluxcomponents[f\"{filters}\"] = componentsflux[componentsflux[\"FILTER\"] == filters].drop(componentsflux.keys()[:3], axis=1)\n",
    "    errorfluxcomponents[f\"{filters}\"] = ecomponentsflux[ecomponentsflux[\"FILTER\"] == filters].drop(componentsflux.keys()[:3], axis=1)\n",
    "    dateobs[f\"{filters}\"] = merged_dftot[0][merged_dftot[0][\"FILTER\"] == filters][\"JD-OBS\"]\n",
    "    ids[f\"{filters}\"] = merged_dftot[0][merged_dftot[0][\"FILTER\"] == filters][\"IMAGEID\"]\n",
    "print(unique_values) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab7863e-1bef-420b-a27e-39ebd19be422",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f8fee1-e7b2-4f04-b99c-364a85b80cb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "difmag = -2.5*(fluxcomponents[\"Lum\"][\"FLUX\"]/fluxstars[\"Lum\"][\"FLUX_G\"]).apply(lambda x: np.log10(x))\n",
    "plt.plot(dateobs[\"Lum\"],difmag,linewidth=0, marker=\".\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0f1ed2-d6f2-43c4-9625-98990052d307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for differential photometry between stars with the flux and the dateobs in arrays\n",
    "def star_diff_phot(fluxstars, dateobs, diferent_filters, starsname = False): \n",
    "    # fluxstars: array separated by filters, in each filter the flux values of each star in different arrays, for a star each value of flux corresponds to a different image.\n",
    "    # dateobs: array separated by filters, each date corresponds to a different image.\n",
    "    # starsname: array with names of the stars, default the stars are named with numbers.\n",
    "    # diferent_filters: array with the filters\n",
    "    \n",
    "    if starsname == False: # Stars named with numbers\n",
    "        starsname = [str(i) for i in range(len(fluxstars[diferent_filters[0]].keys()))]\n",
    "    \n",
    "    diff_phot = {} # Diff. phot values\n",
    "    diff_phot_names = {} # Diff. phot star combinations names\n",
    "    diff_phot_dates = {} # Dates for each diff. phot value\n",
    "    \n",
    "    for num_stars in range(1, len(starsname)): # Differential photometry using different numbers of stars like reference stars\n",
    "        diff_phot[num_stars] = {} \n",
    "        diff_phot_names[num_stars] = {}\n",
    "        diff_phot_dates[num_stars] = {}\n",
    "                           \n",
    "        for i, flux_star in enumerate(fluxstars):  # Separated for each filter\n",
    "            diff_phot[num_stars]['filter_' + diferent_filters[i]] = []\n",
    "            diff_phot_names[num_stars]['filter_' + diferent_filters[i]] = []\n",
    "            diff_phot_dates[num_stars]['filter_' + diferent_filters[i]] = []  \n",
    "            \n",
    "            for j, star_flux in enumerate(fluxstars[flux_star]): # Differential photometry of one star in front of the rest\n",
    "                for combo in combinations(np.delete(fluxstars[flux_star].keys(), j), num_stars): # Combinations of the stars used like reference stars\n",
    "                    diffphot = -2.5 * (sum(fluxstars[flux_star][k] for k in combo) / fluxstars[flux_star][star_flux]).apply(lambda x: np.log10(x))\n",
    "                    diff_phot[num_stars]['filter_' + diferent_filters[i]].append(diffphot)\n",
    "                    diff_phot_names[num_stars]['filter_' + diferent_filters[i]].append(starsname[j] + ''.join(k[-1] for k in combo))\n",
    "                    diff_phot_dates[num_stars]['filter_' + diferent_filters[i]].append(np.float64(dateobs[flux_star]))\n",
    "\n",
    "    return diff_phot, diff_phot_names, diff_phot_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cfb2db-5d36-453d-8a0e-e931265d19c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_diff_phot(fluxstars, errorfluxstars, diferent_filters, starsname = False):\n",
    "    if starsname == False: # Stars named with numbers\n",
    "        starsname = [str(i) for i in range(len(fluxstars[0]))]\n",
    "    \n",
    "    error = {}\n",
    "    errordiff_phot_names = {}\n",
    "    for num_stars in range(1, len(starsname)): # Differential photometry using different numbers of stars like reference stars\n",
    "        error[num_stars] = {} \n",
    "        errordiff_phot_names[num_stars] = {}                  \n",
    "        for i, flux_star in enumerate(fluxstars):  # Separated for each filter\n",
    "            error[num_stars]['filter_' + diferent_filters[i]] = []\n",
    "            errordiff_phot_names[num_stars]['filter_' + diferent_filters[i]] = []\n",
    "            for j, star_flux in enumerate(fluxstars[flux_star]): # Differential photometry of one star in front of the rest\n",
    "                for combo in combinations(np.delete(fluxstars[flux_star].keys(), j), num_stars): # Combinations of the stars used like reference stars\n",
    "                    errordiffphot = 2.5 * np.log10(np.e) * (sum((errorfluxstars[flux_star][\"D\"+k]**2) for k in combo)/((sum(fluxstars[flux_star][k] for k in combo))**2) + (errorfluxstars[flux_star][\"D\"+star_flux]/fluxstars[flux_star][star_flux])**2).apply(lambda x: np.sqrt(x)) \n",
    "                    error[num_stars]['filter_' + diferent_filters[i]].append(errordiffphot)\n",
    "                    errordiff_phot_names[num_stars]['filter_' + diferent_filters[i]].append(starsname[j] + ''.join(k[-1] for k in combo))\n",
    "\n",
    "    return error, errordiff_phot_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b746ea1b-0adc-48be-ad5d-7fbb6465eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for differential photometry between the components of the lens and the stars with the flux and the dateobs in arrays\n",
    "def component_diff_phot(fluxstars, fluxcomp, dateobs, diferent_filters, starsname = False, compname = False): \n",
    "    # fluxstars: array separated by filters, in each filter the flux values of each star in different arrays, for a star each value of flux corresponds to a different image.\n",
    "    # fluxcomp: array separated by filters, in each filter the flux values of each component in different arrays, for a component each value of flux corresponds to a different image.\n",
    "    # dateobs: array separated by filters, each date corresponds to a different image.\n",
    "    # starsname: array with names of the stars, default the stars are named with numbers.\n",
    "    # compname: array with names of the components, default the components are named with numbers.\n",
    "    # diferent_filters: array with the filters\n",
    "    # count=0\n",
    "    # count2=0\n",
    "    if starsname == False: # Stars named with numbers\n",
    "        starsname = [str(i) for i in range(len(fluxstars[diferent_filters[0]].keys()))]\n",
    "        \n",
    "    if compname == False: # Components named with numbers\n",
    "        compname = [str(i) for i in range(len(fluxcomp[diferent_filters[0]].keys()))]\n",
    "    \n",
    "    diff_photA = {} # Diff. phot values\n",
    "    diff_phot_namesA = {} # Diff. phot components and stars combinations names\n",
    "    diff_phot_datesA = {} # Dates for each diff. phot value\n",
    "    \n",
    "    diff_photB = {} # Diff. phot values\n",
    "    diff_phot_namesB = {} # Diff. phot components and stars combinations names\n",
    "    diff_phot_datesB = {} # Dates for each diff. phot value\n",
    "    \n",
    "    for num_stars in range(1, len(starsname)+1): # Differential photometry using different numbers of stars like reference stars\n",
    "        diff_photA[num_stars] = {} \n",
    "        diff_phot_namesA[num_stars] = {}\n",
    "        diff_phot_datesA[num_stars] = {}\n",
    "        \n",
    "        diff_photB[num_stars] = {} \n",
    "        diff_phot_namesB[num_stars] = {}\n",
    "        diff_phot_datesB[num_stars] = {}\n",
    "                           \n",
    "        for i, filters in enumerate(fluxstars):  # Separated for each filter\n",
    "            diff_photA[num_stars]['filter_' + diferent_filters[i]] = []\n",
    "            diff_phot_namesA[num_stars]['filter_' + diferent_filters[i]] = []\n",
    "            diff_phot_datesA[num_stars]['filter_' + diferent_filters[i]] = []  \n",
    "            \n",
    "            diff_photB[num_stars]['filter_' + diferent_filters[i]] = []\n",
    "            diff_phot_namesB[num_stars]['filter_' + diferent_filters[i]] = []\n",
    "            diff_phot_datesB[num_stars]['filter_' + diferent_filters[i]] = [] \n",
    "            \n",
    "            for j, comp_flux in enumerate(fluxcomp[filters]): # Differential photometry of one component in front of the stars\n",
    "                for combo in combinations(fluxstars[filters].keys(), num_stars): # Combinations of the stars used like reference stars\n",
    "                    if j==0:\n",
    "                        diffphotA = -2.5 * (fluxcomp[filters][comp_flux] / sum(fluxstars[filters][k] for k in combo)).apply(lambda x: np.log10(x)) \n",
    "                        diff_photA[num_stars]['filter_' + diferent_filters[i]].append(np.array(diffphotA))\n",
    "                        diff_phot_namesA[num_stars]['filter_' + diferent_filters[i]].append(compname[j] + ''.join(k[-1] for k in combo))\n",
    "                        diff_phot_datesA[num_stars]['filter_' + diferent_filters[i]].append(np.float64(dateobs[filters]))\n",
    "                        # if count==0:\n",
    "                        #     print(diffphotA,np.float64(dateobs[filters]))\n",
    "                        # count+=1\n",
    "                    else:\n",
    "                        \n",
    "                        diffphotB = -2.5 * (fluxcomp[filters][comp_flux] / sum(fluxstars[filters][k] for k in combo)).apply(lambda x: np.log10(x)) \n",
    "                        diff_photB[num_stars]['filter_' + diferent_filters[i]].append(np.array(diffphotB))\n",
    "                        diff_phot_namesB[num_stars]['filter_' + diferent_filters[i]].append(compname[j] + ''.join(k[-1] for k in combo))\n",
    "                        diff_phot_datesB[num_stars]['filter_' + diferent_filters[i]].append(np.float64(dateobs[filters]))\n",
    "                        # if count2==0:\n",
    "                        #     print(diffphotB,np.float64(dateobs[filters]))\n",
    "                        # count2+=1\n",
    "    return diff_photA, diff_phot_namesA, diff_phot_datesA, diff_photB, diff_phot_namesB, diff_phot_datesB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf2d447-7613-4b53-be34-a77eca520a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for compute the scale factors for the σ of differential photometry between components and stars\n",
    "def scalefactors(fluxstars, errorfluxstars, fluxcomp, errorfluxcomp, diferent_filters, starsname = False):\n",
    "    # fluxstars: array separated by filters, in each filter the flux values of each star in different arrays, for a star each value of flux corresponds to a different image.\n",
    "    # fluxcomp: array separated by filters, in each filter the flux values of each component in different arrays, for a component each value of flux corresponds to a different image.\n",
    "    # diferent_filters: array with the filters\n",
    "    # starsname: array with names of the stars, default the stars are named with numbers.\n",
    "    # compname: array with names of the components, default the components are named with numbers.\n",
    "    # diferent_filters: array with the filters\n",
    "    \n",
    "    if starsname == False: # Stars named with numbers\n",
    "        starsname = [str(i) for i in range(len(fluxstars[diferent_filters[0]].keys()))]\n",
    "    \n",
    "    scale_factorsA = {} # Scale factors (SF) -> σ_comp = SF * σ_stars_after_plot\n",
    "    scale_factorsB = {} \n",
    "    scale_factors_namesA = {} # To know which components and which stars have been used \n",
    "    scale_factors_namesB = {}\n",
    "    \n",
    "    for num_stars in range(1, len(starsname)): # Number of reference stars\n",
    "        scale_factorsA[num_stars] = {}\n",
    "        scale_factors_namesA[num_stars] = {}\n",
    "        scale_factorsB[num_stars] = {}\n",
    "        scale_factors_namesB[num_stars] = {}\n",
    "        \n",
    "        for i, flux_star in enumerate(fluxstars): # Separated for each filter\n",
    "            scale_factorsA[num_stars]['filter_' + diferent_filters[i]] = []\n",
    "            scale_factors_namesA[num_stars]['filter_' + diferent_filters[i]] = []\n",
    "            scale_factorsB[num_stars]['filter_' + diferent_filters[i]] = []\n",
    "            scale_factors_namesB[num_stars]['filter_' + diferent_filters[i]] = []\n",
    "            \n",
    "            for j, comp_flux in enumerate(fluxcomp[flux_star]):\n",
    "                for combo in combinations(fluxstars[flux_star].keys(), num_stars): # Implementation the sum of stars' fluxes\n",
    "                    for l, s in enumerate(fluxstars[flux_star]): \n",
    "                        if s not in combo: # Stars no used in the combo to compute the σ_stars_from_flux_error needed for SF = σ_stars_from_flux_error/σ_comp_from_flux_error\n",
    "                            # scale_factors[num_stars]['filter_' + diferent_filters[i]].append((fluxstars[flux_star][s] / fluxcomp[flux_star][comp_flux]) ** 2 * (\n",
    "                            #             ((sum(fluxstars[flux_star][k] for k in combo))**2 * (errorfluxcomp[flux_star][\"D\"+comp_flux])**2 +\n",
    "                            #              (fluxcomp[flux_star][comp_flux])**2 * (sum(errorfluxstars[flux_star][\"D\"+k] for k in combo))**2) /\n",
    "                            #             (fluxstars[flux_star][s]** 2 * (sum(errorfluxstars[flux_star][\"D\"+k] for k in combo))**2 +\n",
    "                            #              errorfluxstars[flux_star][\"D\"+s]** 2 * (sum(fluxstars[flux_star][k] for k in combo))**2)))\n",
    "                            if j == 0: # A\n",
    "                                scale_factorsA[num_stars]['filter_' + diferent_filters[i]].append((fluxstars[flux_star][s] / fluxcomp[flux_star][comp_flux]) ** 2 * (\n",
    "                                        ((sum(fluxstars[flux_star][k] for k in combo))**2 * (errorfluxcomp[flux_star][\"D\"+comp_flux])**2 +\n",
    "                                         (fluxcomp[flux_star][comp_flux])**2 * (sum(errorfluxstars[flux_star][\"D\"+k] for k in combo))**2) /\n",
    "                                        (fluxstars[flux_star][s]** 2 * (sum(errorfluxstars[flux_star][\"D\"+k] for k in combo))**2 +\n",
    "                                         errorfluxstars[flux_star][\"D\"+s]** 2 * (sum(fluxstars[flux_star][k] for k in combo))**2)))\n",
    "                                scale_factors_namesA[num_stars]['filter_' + diferent_filters[i]].append(\"A\" + starsname[l] + ''.join(k[-1] for k in combo))\n",
    "                            else: # B\n",
    "                                scale_factors_namesB[num_stars]['filter_' + diferent_filters[i]].append(\"B\" + starsname[l] + ''.join(k[-1] for k in combo))   \n",
    "                                scale_factorsB[num_stars]['filter_' + diferent_filters[i]].append((fluxstars[flux_star][s] / fluxcomp[flux_star][comp_flux]) ** 2 * (\n",
    "                                        ((sum(fluxstars[flux_star][k] for k in combo))**2 * (errorfluxcomp[flux_star][\"D\"+comp_flux])**2 +\n",
    "                                         (fluxcomp[flux_star][comp_flux])**2 * (sum(errorfluxstars[flux_star][\"D\"+k] for k in combo))**2) /\n",
    "                                        (fluxstars[flux_star][s]** 2 * (sum(errorfluxstars[flux_star][\"D\"+k] for k in combo))**2 +\n",
    "                                         errorfluxstars[flux_star][\"D\"+s]** 2 * (sum(fluxstars[flux_star][k] for k in combo))**2)))\n",
    "    return scale_factorsA, scale_factors_namesA, scale_factorsB, scale_factors_namesB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a8535-5e39-488f-91c3-c21354c95569",
   "metadata": {},
   "outputs": [],
   "source": [
    "compname = [\"A\",\"B\"]\n",
    "starsname = [\"D\", \"E\", \"G\", \"I\", \"K\"]\n",
    "diff_phot, diff_phot_names, diff_phot_dates = star_diff_phot(fluxstars, dateobs, unique_values, starsname)\n",
    "diff_phot_compA, diff_phot_names_compA, diff_phot_dates_compA, diff_phot_compB, diff_phot_names_compB, diff_phot_dates_compB = component_diff_phot(fluxstars, fluxcomponents, dateobs, unique_values, starsname, compname)\n",
    "scale_factorsA, scale_factors_namesA, scale_factorsB, scale_factors_namesB = scalefactors(fluxstars, errorfluxstars, fluxcomponents, errorfluxcomponents, unique_values, starsname)\n",
    "error, errordiff_phot_names = error_diff_phot(fluxstars, errorfluxstars, unique_values, starsname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c4e21c-73b0-41a8-96bb-c2eae56f428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[250,250,250,50]\n",
    "for o, t in enumerate(diff_phot):\n",
    "    print(len(diff_phot[t]), len(diff_phot[t][\"filter_Lum\"]))\n",
    "    \n",
    "    figure, axis = plt.subplots(len(diff_phot[t]), len(diff_phot[t][\"filter_Lum\"]),figsize=(a[o], 60))\n",
    "    figure.tight_layout(pad=3.5)\n",
    "    for i, filtre in enumerate(diff_phot[t]):\n",
    "        for j, phot in enumerate(diff_phot[t][filtre]):\n",
    "        \n",
    "            axis[i][j].errorbar(diff_phot_dates[t]['filter_' + unique_values[i]][j]-2460000.0, phot, yerr=np.std((phot[np.logical_not(np.isnan(phot))])), elinewidth=0.75, linewidth=0,   marker=\".\", label = f\"σ = {np.std((phot[np.logical_not(np.isnan(phot))]))}\")\n",
    "            axis[i][j].legend()\n",
    "            #axis[i][j].set_ylim([np.mean(group3_2[i][j][np.logical_not(np.isnan(group3_2[i][j]))])-10*np.std(group3_2[i][j][np.logical_not(np.isnan(group3_2[i][j]))]),np.mean(group3_2[i][j][np.logical_not(np.isnan(group3_2[i][j]))])+10*np.std(group3_2[i][j][np.logical_not(np.isnan(group3_2[i][j]))])])\n",
    "            axis[i][j].set(xlabel='Time JD-2460000', ylabel='Phot. Diff.')\n",
    "            axis[i][j].set_title(\"Filter \"+unique_values[i]+ \" star \" + diff_phot_names[t]['filter_' + unique_values[i]][j][0]+ \" and ref. star \" + diff_phot_names[t]['filter_' + unique_values[i]][j][1:] )\n",
    "    \n",
    "    plt.show()\n",
    "    #plt.savefig('diff_phot_stars_astroDB'+str(t)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d2808-dfea-4995-86af-ec056f112add",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract outliers\n",
    "def exctract_outliers(data, min_quantile, max_quantile):\n",
    "    \n",
    "    deletepositions=[]\n",
    "    \n",
    "    for k in data:\n",
    "        if k < np.quantile(data, min_quantile) or k > np.quantile(data, max_quantile):                                    \n",
    "            deletepositions.append(np.where(data == k)[0][0])\n",
    "            \n",
    "    return deletepositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e5c958-92ce-40e5-9902-32d993efec21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def exctract_outliers2(data, time, min_quantile, max_quantile):\n",
    "    deletepositions=[]\n",
    "    \n",
    "    df = pd.DataFrame({'X': time, 'Y': data})\n",
    "    \n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(time.reshape(-1, 1), data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Fit the model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    # Predict on the training set\n",
    "    df['Predicted'] = model.predict(time.reshape(-1, 1))\n",
    "    \n",
    "    # Calculate residuals\n",
    "    df['Residuals'] = df['Y'] - df['Predicted']\n",
    "\n",
    "    # Standardize residuals\n",
    "    df['StdResiduals'] = (df['Residuals'] - df['Residuals'].mean()) / df['Residuals'].std()\n",
    "\n",
    "    # Identify outliers using Z-score method (threshold |Z| > 2 for this example)\n",
    "    outliers = df[np.abs(df['StdResiduals']) > 2]\n",
    "    \n",
    "    for k in outliers[\"Y\"]:\n",
    "        deletepositions.append(np.where(data == k)[0][0])\n",
    "    # print(len(df['Predicted']), len(data), len(time))\n",
    "    return deletepositions, df['Predicted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7f6e61-3d4d-421c-9070-7a58ef2ea61c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __data_time_binning(data, time, mjd_ini, mjd_end, time_interval_hours, parameter, parameter_error):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: panda dataframe. Mandatory to have columns [time,parameter,parameter_error] i.e. ['MJD','MAG','eMAG']\n",
    "    time: column time name \n",
    "    mjd_ini/mjd_end: MJD initial/final float\n",
    "    time_interval_hours: time interval units hours float\n",
    "    parameter: column parameter name to do stats string\n",
    "    parameter_error: column parameter name with individual errors string\n",
    "    \n",
    "    \n",
    "    Return\n",
    "    ----------\n",
    "    result_df: panda df [time+'_min', time+'_max', time+'_median',time+'std',time+'_n', parameter+'_median', parameter+'_std', parameter+'_n',time+'_central','e'+time]\n",
    "    \"\"\"    \n",
    "    MJD_bins=int((mjd_end-mjd_ini)*24/time_interval_hours)\n",
    "    \n",
    "    x_median,y_median,n_x,n_y = __binXY(data[time],data[parameter],statistic='median',xbins=MJD_bins,xrange=None)\n",
    "    # print(x_median,y_median,n_x,n_y)\n",
    "    x_std,y_std,n_x,n_y = __binXY(data[time],data[parameter],statistic='std',xbins=MJD_bins,xrange=None)\n",
    "    x_min,y_min,n_x,n_y = __binXY(data[time],data[parameter],statistic='min',xbins=MJD_bins,xrange=None)\n",
    "    x_max,y_max,n_x,n_y = __binXY(data[time],data[parameter],statistic='max',xbins=MJD_bins,xrange=None)\n",
    "    data_bin=pd.DataFrame({time+'_min': x_min, time+'_max': x_max, time+'_median': x_median, time+'_std': x_std, time+'_n': n_x, parameter+'_median': y_median, parameter+'_std': y_std, parameter+'_n': n_y})\n",
    "    data_bin = data_bin.dropna() # dropping NaN lines\n",
    "    data_bin['e'+parameter] = data_bin[parameter+'_std'] / np.sqrt(data_bin[parameter+'_n'])\n",
    "    data_bin[time+'_central']=data_bin[time+'_min']+(data_bin[time+'_max']-data_bin[time+'_min'])/2\n",
    "    data_bin['e'+time]=(data_bin[time+'_max']-data_bin[time+'_min'])/2\n",
    "    return(data_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29386682-f1ea-4936-bcba-2a952ce8f47c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def __binXY(x,y,statistic='mean',xbins=10,xrange=None):\n",
    "    \"\"\"\n",
    "    Finds statistical value of x and y values in each x bin. \n",
    "    Returns the same type of statistic for both x and y.\n",
    "    See scipy.stats.binned_statistic() for options.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array\n",
    "        x values.\n",
    "    y : array\n",
    "        y values.\n",
    "    statistic : string or callable, optional\n",
    "        See documentation for scipy.stats.binned_statistic(). Default is mean.\n",
    "    xbins : int or sequence of scalars, optional\n",
    "        If xbins is an integer, it is the number of equal bins within xrange.\n",
    "        If xbins is an array, then it is the location of xbin edges, similar\n",
    "        to definitions used by np.histogram. Default is 10 bins.\n",
    "        All but the last (righthand-most) bin is half-open. In other words, if \n",
    "        bins is [1, 2, 3, 4], then the first bin is [1, 2) (including 1, but \n",
    "        excluding 2) and the second [2, 3). The last bin, however, is [3, 4], \n",
    "        which includes 4.    \n",
    "        \n",
    "    xrange : (float, float) or [(float, float)], optional\n",
    "        The lower and upper range of the bins. If not provided, range is \n",
    "        simply (x.min(), x.max()). Values outside the range are ignored.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    x_stat : array\n",
    "        The x statistic (e.g. mean) in each bin. \n",
    "    y_stat : array\n",
    "        The y statistic (e.g. mean) in each bin.       \n",
    "    n_x : array of dtype int\n",
    "        The count of x values in each bin.\n",
    "    n_y : array of dtype int\n",
    "        The count of y values in each bin.        \n",
    "        \"\"\"\n",
    "    x_stat, xbin_edges, binnumber = stats.binned_statistic(x, x, \n",
    "                                 statistic=statistic, bins=xbins, range=xrange)\n",
    "    #print(x_stat)\n",
    "    y_stat, xbin_edges, binnumber = stats.binned_statistic(x, y, \n",
    "                                 statistic=statistic, bins=xbins, range=xrange)\n",
    "    n_x, xbin_edges, binnumber = stats.binned_statistic(x, x, \n",
    "                                 statistic='count', bins=xbins, range=xrange)\n",
    "    n_y, xbin_edges, binnumber = stats.binned_statistic(x, y, \n",
    "                                 statistic='count', bins=xbins, range=xrange)\n",
    "            \n",
    "    return x_stat, y_stat, n_x, n_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0cd293-e3c6-401f-b4bc-5102387e16ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOTS COMPONENTS + STARS + SCALE FACTORS, substract outliers and binning (improve it)\n",
    "import copy\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import statistics as stat\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "a=[250,400,250,100]\n",
    "for o, t in enumerate(scale_factors_namesA):\n",
    "    figure, axis = plt.subplots(len(scale_factors_namesA[t]), int(len(scale_factors_namesA[t][\"filter_Lum\"])),figsize=(a[o], 60))\n",
    "    figure.tight_layout(pad=3.5)\n",
    "    for i, filtre in enumerate(scale_factors_namesA[t]):\n",
    "        for j, l in enumerate(scale_factors_namesA[t][filtre]):\n",
    "            for r, n in enumerate(diff_phot_names[t]['filter_' + unique_values[i]]):\n",
    "                if n==l[1:]:\n",
    "                    for g, phot in enumerate(diff_phot_compA[t]['filter_' + unique_values[i]]):\n",
    "                        \n",
    "                        if l[0]==diff_phot_names_compA[t]['filter_' + unique_values[i]][g][0] and  diff_phot_names_compA[t]['filter_' + unique_values[i]][g][1:]==n[1:]: \n",
    "                            \n",
    "                            photA = copy.deepcopy(phot)\n",
    "                            datesA = copy.deepcopy(diff_phot_dates_compA[t]['filter_' + unique_values[i]][g])\n",
    "                            sfA = copy.deepcopy(scale_factorsA[t][filtre][j])\n",
    "                            \n",
    "                            deletepositions0 = exctract_outliers(data = photA,  min_quantile = 0.03, max_quantile = 0.97)\n",
    "                            photA = np.delete(photA, deletepositions0)\n",
    "                            datesA = np.delete(datesA, deletepositions0)\n",
    "                            sfA = np.delete(sfA, deletepositions0)\n",
    "                            \n",
    "                            deletepositions, pred1 = exctract_outliers2(data = photA, time = datesA,  min_quantile = 0.03, max_quantile = 0.97)\n",
    "                            # print(len(deletepositions), len(pred1), len(datesA), len(photA))\n",
    "                            photA = np.delete(photA, deletepositions)\n",
    "                            datesA = np.delete(datesA, deletepositions)\n",
    "                            sfA = np.delete(sfA, deletepositions)\n",
    "                            pred1 = np.delete(pred1, deletepositions)\n",
    "                            \n",
    "                            # print(len(pred1), len(datesA), len(photA))\n",
    "                            \n",
    "                            photB = copy.deepcopy(diff_phot_compB[t]['filter_' + unique_values[i]][g])\n",
    "                            datesB = copy.deepcopy(diff_phot_dates_compB[t]['filter_' + unique_values[i]][g])\n",
    "                            sfB = copy.deepcopy(scale_factorsB[t][filtre][j])\n",
    "                              \n",
    "                            deletepositions02 = exctract_outliers(data = diff_phot_compB[t]['filter_' + unique_values[i]][g],min_quantile = 0.03, max_quantile = 0.97)\n",
    "                            photB = np.delete(photB, deletepositions02)\n",
    "                            datesB = np.delete(datesB, deletepositions02)     \n",
    "                            sfB = np.delete(sfB, deletepositions02)\n",
    "                            \n",
    "                            deletepositions2, pred2 = exctract_outliers2(data = photB, time = datesB, min_quantile = 0.03, max_quantile = 0.97)\n",
    "                            # print(len(pred2), len(datesB), len(photB))                     \n",
    "                            photB = np.delete(photB, deletepositions2)\n",
    "                            datesB = np.delete(datesB, deletepositions2)     \n",
    "                            sfB = np.delete(sfB, deletepositions2)  \n",
    "                            pred2 = np.delete(pred2, deletepositions2)\n",
    "                            # print(len(pred2), len(datesB), len(photB))\n",
    "                            \n",
    "                            deletepositions3=[]\n",
    "                            for u, x in enumerate(sfA):\n",
    "                                if x > (stat.mode(sfA)+stat.mode(sfA)/2):# or x < (stat.mode(sfA)-stat.mode(sfA)/2):\n",
    "                                    deletepositions3.append(u)\n",
    "                                                                       \n",
    "                            photA = np.delete(photA, deletepositions3)\n",
    "                            datesA = np.delete(datesA, deletepositions3)\n",
    "                            sfA = np.delete(sfA, deletepositions3)\n",
    "                            pred1 = np.delete(pred1, deletepositions3)\n",
    "\n",
    "                            \n",
    "                            deletepositions4=[]\n",
    "                            for u, x in enumerate(sfB):\n",
    "                                if x > (stat.mode(sfB)+stat.mode(sfB)/2):# or x < (stat.mode(sfB)-stat.mode(sfB)):\n",
    "                                    deletepositions4.append(u)\n",
    "                            photB = np.delete(photB, deletepositions4)\n",
    "                            datesB = np.delete(datesB, deletepositions4)\n",
    "                            sfB = np.delete(sfB, deletepositions4)\n",
    "                            pred2 = np.delete(pred2, deletepositions4)\n",
    "\n",
    "                        \n",
    "                            err=diff_phot[t][filtre][r][np.logical_not(np.isnan(diff_phot[t][filtre][r]))]\n",
    "                            #deletepositions5=[]\n",
    "                            #for k in diff_phot[t][filtre][r][np.logical_not(np.isnan(diff_phot[t][filtre][r]))]:\n",
    "                                #if k < np.quantile(err, 0.1) or k > np.quantile(err, 0.9):     \n",
    "                                    #deletepositions5.append(np.where(err == k)[0][0]) \n",
    "                            \n",
    "                            deletepositions5 = exctract_outliers(data = diff_phot[t][filtre][r][np.logical_not(np.isnan(diff_phot[t][filtre][r]))], min_quantile = 0.1, max_quantile = 0.9)\n",
    "                            \n",
    "                            err = np.delete(err, deletepositions5)\n",
    "                    \n",
    "                            lista3= zip(datesA, photA, sfA*np.std(err))\n",
    "                            # print(type(lista3))\n",
    "                            lista4= zip(datesB, photB, sfB*np.std(err))\n",
    "                            dfA = pd.DataFrame(lista3, columns=['MJD','MAG','eMAG'])\n",
    "                            dfB = pd.DataFrame(lista4, columns=['MJD','MAG','eMAG'])\n",
    "                                #print(dfA)\n",
    "                                \n",
    "                            data_binA = __data_time_binning(data=dfA, time='MJD', mjd_ini=min(datesA), mjd_end=max(datesA), time_interval_hours=24.0, parameter='MAG', parameter_error='eMAG')\n",
    "                            data_binB = __data_time_binning(data=dfB, time='MJD', mjd_ini=min(datesB), mjd_end=max(datesB), time_interval_hours=24.0, parameter='MAG', parameter_error='eMAG')\n",
    "                     \n",
    "                            # datesA2, photA2, ephotA2 = bin_flux_data_julian(photA, datesA, 24)\n",
    "                            # datesB2, photB2, ephotB2 = bin_flux_data_julian(photB, datesB, 24)\n",
    "                            # datesA3, sfA2, ee = bin_flux_data_julian(sfA, datesA, 24)\n",
    "                            # datesB3, sfB2, ee = bin_flux_data_julian(sfB, datesB, 24)\n",
    "                            \n",
    "                            if i == 1:\n",
    "                                if j==0:\n",
    "                                    finalA=data_binA[\"MAG_median\"]\n",
    "                                    finalB=data_binB[\"MAG_median\"]\n",
    "                                    finaldataA=data_binA[\"MJD_central\"]\n",
    "                                    finaldataB=data_binB[\"MJD_central\"]\n",
    "                                    \n",
    "                            # for q,w in enumerate(ephotA2):\n",
    "                            #     if w==0:\n",
    "                            #         ephotA2[q]=sfA2[q]*np.std((err))\n",
    "                            # for q,w in enumerate(ephotB2):\n",
    "                            #     if w==0:\n",
    "                            #         ephotB2[q]=sfB2[q]*np.std((err))  pred1\n",
    "                            \n",
    "                            axis[i][j].errorbar((datesA)-2460000.0, photA, yerr=sfA*np.std((err)), elinewidth=0.75, linewidth=0,   marker=\".\", label = f\"Component A ($σA _i = \\Gamma ^{2}_i $ x {np.std((err))})\") # ({np.mean(sfA)})*np.std((diff_phot[t][filtre][r][np.logical_not(np.isnan(diff_phot[t][filtre][r]))]))\n",
    "                            axis[i][j].errorbar((datesB)-2460000.0, photB, yerr=sfB*np.std((err)), elinewidth=0.75, linewidth=0,   marker=\".\", label = f\"Component B ($σB _i = \\Gamma ^{2}_i $ x {np.std((err))})\") #({np.mean(sfB)})*np.std((diff_phot[t][filtre][r][np.logical_not(np.isnan(diff_phot[t][filtre][r]))]))\n",
    "                            \n",
    "                            axis[i][j].errorbar((data_binA[\"MJD_central\"])-2460000.0, data_binA[\"MAG_median\"], xerr=data_binA[\"eMJD\"], yerr=data_binA[\"eMAG\"], elinewidth=0.75, linewidth=0, ms=10,  marker=\".\", mfc=\"black\",mec=\"black\", ecolor=\"black\")#, label = f\"$σA _i = \\Gamma ^{2}_i $ x {np.std((diff_phot[t][filtre][r][np.logical_not(np.isnan(diff_phot[t][filtre][r]))]))}\") # ({np.mean(sfA)})*np.std((diff_phot[t][filtre][r][np.logical_not(np.isnan(diff_phot[t][filtre][r]))]))\n",
    "                            axis[i][j].errorbar((data_binB[\"MJD_central\"])-2460000.0, data_binB[\"MAG_median\"], xerr=data_binB[\"eMJD\"], yerr=data_binB[\"eMAG\"], elinewidth=0.75, linewidth=0, ms=10,  marker=\".\", mfc=\"black\",mec=\"black\", ecolor=\"black\")\n",
    "                            \n",
    "                            axis[i][j].locator_params(axis='x', nbins=50)\n",
    "                            \n",
    "                            axis[i][j].legend()\n",
    "                            axis[i][j].set(xlabel='Time JD-2460000', ylabel='Phot. Diff.')\n",
    "                            axis[i][j].set_title(\"Filter \"+unique_values[i] + \" comp. \"+ diff_phot_names_compA[t]['filter_' + unique_values[i]][g][0]+ \" and \" + diff_phot_names_compB[t]['filter_' + unique_values[i]][g][0]+ \" and ref. star \" + diff_phot_names_compA[t]['filter_' + unique_values[i]][g][1:] +\", $\\Gamma ^2 $ using \"+ l+ \" and \"+ (scale_factors_namesB[t][filtre][j]) +\", σ_stars_\"+ n )\n",
    "    \n",
    "    # plt.savefig('ejemplo'+'.jpeg')\n",
    "    break\n",
    "    # plt.savefig('diff_phot_components_error_binning'+str(t)+'.jpeg')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
